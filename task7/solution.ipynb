{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  собрать всю информацию по каждому пользователю в отдельной\n",
    "витрине, а также на основе имеющихся данных посчитать:\n",
    " количество покупок,\n",
    " количество потраченных средств,\n",
    " средний рейтинг по продукту,\n",
    " наивысший продукт по рейтингу,\n",
    " самый популярный тип продукта,\n",
    " количество отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "csv_folder = './src'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_preference = pd.read_csv(os.path.join(csv_folder,'contact_preference.csv'),sep=';')\n",
    "customer_preferenced_contact_type = pd.read_csv(os.path.join(csv_folder,'customer_preferenced_contact_type.csv'),sep=';')\n",
    "customer = pd.read_csv(os.path.join(csv_folder,'customer.csv'),sep=';')\n",
    "customers_segments = pd.read_csv(os.path.join(csv_folder,'customers_segmetns.csv'),sep=';')\n",
    "location = pd.read_csv(os.path.join(csv_folder,'location.csv'),sep=';')\n",
    "product_feedback = pd.read_csv(os.path.join(csv_folder,'product_feedback.csv'),sep=';')\n",
    "product = pd.read_csv(os.path.join(csv_folder,'product.csv'),sep=';')\n",
    "purchase = pd.read_csv(os.path.join(csv_folder,'purchase.csv'),sep=';')\n",
    "segment = pd.read_csv(os.path.join(csv_folder,'segment.csv'),sep=';')\n",
    "service_feedback = pd.read_csv(os.path.join(csv_folder,'service_feedback.csv'),sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name              email registration_date location_name purchase_date  \\\n",
      "0  Alice  alice@example.com        2023-01-15      New York    2024-01-28   \n",
      "1  Alice  alice@example.com        2023-01-15      New York    2024-01-22   \n",
      "2  Alice  alice@example.com        2023-01-15      New York    2024-01-12   \n",
      "3  Alice  alice@example.com        2023-01-15      New York    2024-01-20   \n",
      "4  Alice  alice@example.com        2023-01-15      New York    2023-09-11   \n",
      "\n",
      "   quantity              product_name category_name  price  customer_rating  \\\n",
      "0       1.0                   Journey         Games  14.99              5.0   \n",
      "1       1.0              Call of Duty         Games  59.99              8.0   \n",
      "2       1.0            The Art of War         Books   7.99              9.0   \n",
      "3       1.0                Life of Pi         Books  10.99             10.0   \n",
      "4       2.0  The Shawshank Redemption        Movies  14.99              6.0   \n",
      "\n",
      "                            review  \\\n",
      "0  Quality is lower than expected.   \n",
      "1        Very happy with my order!   \n",
      "2       Great quality and service!   \n",
      "3               Love this product!   \n",
      "4               Quality is subpar.   \n",
      "\n",
      "                                      comment contact_type  \n",
      "0  Satisfactory service, nothing exceptional.        Email  \n",
      "1  Satisfactory service, nothing exceptional.        Email  \n",
      "2  Satisfactory service, nothing exceptional.        Email  \n",
      "3  Satisfactory service, nothing exceptional.        Email  \n",
      "4  Satisfactory service, nothing exceptional.        Email  \n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(customer, customers_segments, left_on='id', right_on='customer_id', how='left')\n",
    "df = pd.merge(df, customer_preferenced_contact_type, on='customer_id', how='left')\n",
    "df = pd.merge(df, location, on='location_id', how='left')\n",
    "df = pd.merge(df, purchase, left_on='id', right_on='user_id', how='left')\n",
    "df = pd.merge(df, product, left_on='product_id', right_on='id', how='left')\n",
    "df = pd.merge(df, product_feedback, left_on='id_y', right_on='purchase_id', how='left',  suffixes=('_1', '_2'))  # Здесь используйте нужный вам ключ\n",
    "\n",
    "df = pd.merge(df, service_feedback, left_on='customer_id', right_on='customer_id', how='left')\n",
    "# print(df.head())\n",
    "\n",
    "# Добавьте дополнительное объединение с contact_preference, если это необходимо\n",
    "# df = pd.merge(df, customer_preferenced_contact_type, on='customer_id', how='left')\n",
    "df = pd.merge(df, contact_preference, left_on='contact_type_id', right_on='contact_id', how='left')\n",
    "\n",
    "# Удаляем временные столбцы, если необходимо\n",
    "df.drop(columns=['id_x', 'location_id', 'customer_id', 'segment_id', 'contact_type_id', 'contact_id' ,'id' ,'id_1', 'id_2' ,'product_id', 'user_id', 'id_y', 'purchase_id'], inplace=True)\n",
    "df.drop_duplicates()\n",
    "df = df.drop(columns=['rating_y'])  # Удаляем столбец rating_y\n",
    "df.rename(columns={'rating_x': 'customer_rating', 'rating_y': 'product_rating'}, inplace=True)\n",
    "# Проверка на пустые значения\n",
    "\n",
    "# Печатаем результат\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>contact_type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  contact_type_id\n",
       "0            1                1\n",
       "1            1                3\n",
       "2            1                4\n",
       "3            2                2\n",
       "4            2                5"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_preferenced_contact_type.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293813371</td>\n",
       "      <td>19</td>\n",
       "      <td>104</td>\n",
       "      <td>2024-02-09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>696524227</td>\n",
       "      <td>49</td>\n",
       "      <td>90</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14417739</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>2023-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>539614646</td>\n",
       "      <td>45</td>\n",
       "      <td>141</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>691165168</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-10-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  user_id  product_id purchase_date  quantity\n",
       "0  293813371       19         104    2024-02-09         2\n",
       "1  696524227       49          90    2023-06-30         1\n",
       "2   14417739       30          20    2023-09-28         1\n",
       "3  539614646       45         141    2023-04-25         2\n",
       "4  691165168       40          25    2023-10-26         2"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame: contact_preference\n",
      "Columns: ['contact_id', 'contact_type']\n",
      "First 5 rows:\n",
      "    contact_id        contact_type\n",
      "0           1               Email\n",
      "1           2               Phone\n",
      "2           3                 SMS\n",
      "3           4        Social Media\n",
      "4           5  Push Notifications\n",
      "\n",
      "DataFrame: customer\n",
      "Columns: ['id', 'name', 'email', 'location_id', 'registration_date']\n",
      "First 5 rows:\n",
      "    id     name                email  location_id registration_date\n",
      "0   1    Alice    alice@example.com            1        2023-01-15\n",
      "1   2      Bob      bob@example.com            2        2023-02-20\n",
      "2   3  Charlie  charlie@example.com            3        2023-03-10\n",
      "3   4    David    david@example.com            4        2023-04-25\n",
      "4   5      Eva      eva@example.com            5        2023-05-30\n",
      "\n",
      "DataFrame: customers_segmetns\n",
      "Columns: ['customer_id', 'segment_id']\n",
      "First 5 rows:\n",
      "    customer_id  segment_id\n",
      "0            1           2\n",
      "1            2           3\n",
      "2            3           2\n",
      "3            4           1\n",
      "4            5           1\n",
      "\n",
      "DataFrame: customer_preferenced_contact_type\n",
      "Columns: ['customer_id', 'contact_type_id']\n",
      "First 5 rows:\n",
      "    customer_id  contact_type_id\n",
      "0            1                1\n",
      "1            1                3\n",
      "2            1                4\n",
      "3            2                2\n",
      "4            2                5\n",
      "\n",
      "DataFrame: location\n",
      "Columns: ['location_id', 'location_name']\n",
      "First 5 rows:\n",
      "    location_id  location_name\n",
      "0            1       New York\n",
      "1            2  San Francisco\n",
      "2            3    Los Angeles\n",
      "3            4        Chicago\n",
      "4            5        Houston\n",
      "\n",
      "DataFrame: product\n",
      "Columns: ['id', 'product_name', 'category_name', 'price']\n",
      "First 5 rows:\n",
      "    id            product_name category_name  price\n",
      "0   1        The Great Gatsby         Books  10.99\n",
      "1   2                    1984         Books   9.99\n",
      "2   3  The Catcher in the Rye         Books   8.99\n",
      "3   4   To Kill a Mockingbird         Books  12.99\n",
      "4   5     Pride and Prejudice         Books  11.49\n",
      "\n",
      "DataFrame: product_feedback\n",
      "Columns: ['id', 'purchase_id', 'rating', 'review']\n",
      "First 5 rows:\n",
      "    id  purchase_id  rating                                 review\n",
      "0   1  293813371.0       9                     Excellent service!\n",
      "1   2  696524227.0       8       Everything was great, thank you!\n",
      "2   3   14417739.0      10          Outstanding customer service!\n",
      "3   5  691165168.0       6  Quality did not meet my expectations.\n",
      "4   6  633302470.0       5                    Average experience.\n",
      "\n",
      "DataFrame: purchase\n",
      "Columns: ['id', 'user_id', 'product_id', 'purchase_date', 'quantity']\n",
      "First 5 rows:\n",
      "           id  user_id  product_id purchase_date  quantity\n",
      "0  293813371       19         104    2024-02-09         2\n",
      "1  696524227       49          90    2023-06-30         1\n",
      "2   14417739       30          20    2023-09-28         1\n",
      "3  539614646       45         141    2023-04-25         2\n",
      "4  691165168       40          25    2023-10-26         2\n",
      "\n",
      "DataFrame: segment\n",
      "Columns: ['id', 'segment_name', 'discount']\n",
      "First 5 rows:\n",
      "    id segment_name  discount\n",
      "0   1          New         2\n",
      "1   2      Regular         3\n",
      "2   3        Loyal         4\n",
      "3   4          VIP         5\n",
      "4   5     Employer         4\n",
      "\n",
      "DataFrame: service_feedback\n",
      "Columns: ['id', 'customer_id', 'rating', 'comment']\n",
      "First 5 rows:\n",
      "    id  customer_id  rating                                 comment\n",
      "0   1            5       9  Excellent service, very helpful staff!\n",
      "1   2           12       7      Good service, but could be faster.\n",
      "2   3            3      10        Absolutely fantastic experience!\n",
      "3   4           25       8     Satisfied overall, would recommend.\n",
      "4   5           19       6      Service was okay, nothing special.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Укажите путь к папке с CSV-файлами\n",
    "csv_folder = './src'\n",
    "\n",
    "# Словарь для хранения DataFrames\n",
    "all_dataframes = {}\n",
    "\n",
    "# Загрузка всех CSV-файлов\n",
    "for filename in os.listdir(csv_folder):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_folder, filename)\n",
    "        df_name = os.path.splitext(filename)[0]  # Имя DataFrame без расширения\n",
    "        all_dataframes[df_name] = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Просмотр заголовков и первых строк каждого DataFrame\n",
    "def show_frames(dataframes, samples = 5):\n",
    "    for df_name, df in dataframes.items():\n",
    "        print(f\"\\nDataFrame: {df_name}\")\n",
    "        print(\"Columns:\", df.columns.tolist())\n",
    "        print(\"First 5 rows:\\n\", df.head(samples))\n",
    "show_frames(all_dataframes)\n",
    "# Соединяем customer с purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_dataframes = dict.copy(all_dataframes)\n",
    "def frames_merge(main_dataframe, key1, key2, left_on:list, right_on:list, new_key:list) -> dict:\n",
    "    \"\"\"\n",
    "    Функция для объединения двух датафреймов и обновления словаря с таблицами.\n",
    "\n",
    "    Args:\n",
    "        splitted_dataframes (dict): Словарь с DataFrame-ами.\n",
    "        key1 (str): Ключ первого DataFrame в словаре.\n",
    "        key2 (str): Ключ второго DataFrame в словаре.\n",
    "        left_on (str): Поле для соединения из первого DataFrame.\n",
    "        right_on (str): Поле для соединения из второго DataFrame.\n",
    "        new_key (str): Ключ для нового DataFrame после объединения.\n",
    "\n",
    "    Returns:\n",
    "        dict: Обновленный словарь с DataFrame-ами.\n",
    "    \"\"\"\n",
    "    # Объединение двух датафреймов\n",
    "    merged_df = main_dataframe[key1].join(main_dataframe[key2].set_index(right_on), on=left_on, how='left')\n",
    "\n",
    "    \n",
    "    # Удаление старых датафреймов из словаря\n",
    "    main_dataframe.pop(key1)\n",
    "    main_dataframe.pop(key2)\n",
    "    \n",
    "    # Добавление нового объединенного датафрейма в словарь\n",
    "    main_dataframe[new_key] = merged_df\n",
    "    \n",
    "    return main_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame: contact_preference\n",
      "Columns: ['contact_id', 'contact_type']\n",
      "First 5 rows:\n",
      "    contact_id        contact_type\n",
      "0           1               Email\n",
      "1           2               Phone\n",
      "2           3                 SMS\n",
      "3           4        Social Media\n",
      "4           5  Push Notifications\n",
      "\n",
      "DataFrame: customer\n",
      "Columns: ['id', 'name', 'email', 'location_id', 'registration_date']\n",
      "First 5 rows:\n",
      "    id     name                email  location_id registration_date\n",
      "0   1    Alice    alice@example.com            1        2023-01-15\n",
      "1   2      Bob      bob@example.com            2        2023-02-20\n",
      "2   3  Charlie  charlie@example.com            3        2023-03-10\n",
      "3   4    David    david@example.com            4        2023-04-25\n",
      "4   5      Eva      eva@example.com            5        2023-05-30\n",
      "\n",
      "DataFrame: customer_preferenced_contact_type\n",
      "Columns: ['customer_id', 'contact_type_id']\n",
      "First 5 rows:\n",
      "    customer_id  contact_type_id\n",
      "0            1                1\n",
      "1            1                3\n",
      "2            1                4\n",
      "3            2                2\n",
      "4            2                5\n",
      "\n",
      "DataFrame: location\n",
      "Columns: ['location_id', 'location_name']\n",
      "First 5 rows:\n",
      "    location_id  location_name\n",
      "0            1       New York\n",
      "1            2  San Francisco\n",
      "2            3    Los Angeles\n",
      "3            4        Chicago\n",
      "4            5        Houston\n",
      "\n",
      "DataFrame: product\n",
      "Columns: ['id', 'product_name', 'category_name', 'price']\n",
      "First 5 rows:\n",
      "    id            product_name category_name  price\n",
      "0   1        The Great Gatsby         Books  10.99\n",
      "1   2                    1984         Books   9.99\n",
      "2   3  The Catcher in the Rye         Books   8.99\n",
      "3   4   To Kill a Mockingbird         Books  12.99\n",
      "4   5     Pride and Prejudice         Books  11.49\n",
      "\n",
      "DataFrame: product_feedback\n",
      "Columns: ['id', 'purchase_id', 'rating', 'review']\n",
      "First 5 rows:\n",
      "    id  purchase_id  rating                                 review\n",
      "0   1  293813371.0       9                     Excellent service!\n",
      "1   2  696524227.0       8       Everything was great, thank you!\n",
      "2   3   14417739.0      10          Outstanding customer service!\n",
      "3   5  691165168.0       6  Quality did not meet my expectations.\n",
      "4   6  633302470.0       5                    Average experience.\n",
      "\n",
      "DataFrame: purchase\n",
      "Columns: ['id', 'user_id', 'product_id', 'purchase_date', 'quantity']\n",
      "First 5 rows:\n",
      "           id  user_id  product_id purchase_date  quantity\n",
      "0  293813371       19         104    2024-02-09         2\n",
      "1  696524227       49          90    2023-06-30         1\n",
      "2   14417739       30          20    2023-09-28         1\n",
      "3  539614646       45         141    2023-04-25         2\n",
      "4  691165168       40          25    2023-10-26         2\n",
      "\n",
      "DataFrame: service_feedback\n",
      "Columns: ['id', 'customer_id', 'rating', 'comment']\n",
      "First 5 rows:\n",
      "    id  customer_id  rating                                 comment\n",
      "0   1            5       9  Excellent service, very helpful staff!\n",
      "1   2           12       7      Good service, but could be faster.\n",
      "2   3            3      10        Absolutely fantastic experience!\n",
      "3   4           25       8     Satisfied overall, would recommend.\n",
      "4   5           19       6      Service was okay, nothing special.\n",
      "\n",
      "DataFrame: customers_segmetns\n",
      "Columns: ['customer_id', 'segment_id', 'segment_name', 'discount']\n",
      "First 5 rows:\n",
      "    customer_id  segment_id segment_name  discount\n",
      "0            1           2      Regular         3\n",
      "1            2           3        Loyal         4\n",
      "2            3           2      Regular         3\n",
      "3            4           1          New         2\n",
      "4            5           1          New         2\n"
     ]
    }
   ],
   "source": [
    "customers_segments = frames_merge(splitted_dataframes, 'customers_segmetns', 'segment', 'segment_id', 'id', 'customers_segmetns')\n",
    "show_frames(splitted_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame: customer\n",
      "Columns: ['id', 'name', 'email', 'location_id', 'registration_date']\n",
      "First 5 rows:\n",
      "    id     name                email  location_id registration_date\n",
      "0   1    Alice    alice@example.com            1        2023-01-15\n",
      "1   2      Bob      bob@example.com            2        2023-02-20\n",
      "2   3  Charlie  charlie@example.com            3        2023-03-10\n",
      "3   4    David    david@example.com            4        2023-04-25\n",
      "4   5      Eva      eva@example.com            5        2023-05-30\n",
      "\n",
      "DataFrame: location\n",
      "Columns: ['location_id', 'location_name']\n",
      "First 5 rows:\n",
      "    location_id  location_name\n",
      "0            1       New York\n",
      "1            2  San Francisco\n",
      "2            3    Los Angeles\n",
      "3            4        Chicago\n",
      "4            5        Houston\n",
      "\n",
      "DataFrame: product\n",
      "Columns: ['id', 'product_name', 'category_name', 'price']\n",
      "First 5 rows:\n",
      "    id            product_name category_name  price\n",
      "0   1        The Great Gatsby         Books  10.99\n",
      "1   2                    1984         Books   9.99\n",
      "2   3  The Catcher in the Rye         Books   8.99\n",
      "3   4   To Kill a Mockingbird         Books  12.99\n",
      "4   5     Pride and Prejudice         Books  11.49\n",
      "\n",
      "DataFrame: product_feedback\n",
      "Columns: ['id', 'purchase_id', 'rating', 'review']\n",
      "First 5 rows:\n",
      "    id  purchase_id  rating                                 review\n",
      "0   1  293813371.0       9                     Excellent service!\n",
      "1   2  696524227.0       8       Everything was great, thank you!\n",
      "2   3   14417739.0      10          Outstanding customer service!\n",
      "3   5  691165168.0       6  Quality did not meet my expectations.\n",
      "4   6  633302470.0       5                    Average experience.\n",
      "\n",
      "DataFrame: purchase\n",
      "Columns: ['id', 'user_id', 'product_id', 'purchase_date', 'quantity']\n",
      "First 5 rows:\n",
      "           id  user_id  product_id purchase_date  quantity\n",
      "0  293813371       19         104    2024-02-09         2\n",
      "1  696524227       49          90    2023-06-30         1\n",
      "2   14417739       30          20    2023-09-28         1\n",
      "3  539614646       45         141    2023-04-25         2\n",
      "4  691165168       40          25    2023-10-26         2\n",
      "\n",
      "DataFrame: service_feedback\n",
      "Columns: ['id', 'customer_id', 'rating', 'comment']\n",
      "First 5 rows:\n",
      "    id  customer_id  rating                                 comment\n",
      "0   1            5       9  Excellent service, very helpful staff!\n",
      "1   2           12       7      Good service, but could be faster.\n",
      "2   3            3      10        Absolutely fantastic experience!\n",
      "3   4           25       8     Satisfied overall, would recommend.\n",
      "4   5           19       6      Service was okay, nothing special.\n",
      "\n",
      "DataFrame: customers_segmetns\n",
      "Columns: ['customer_id', 'segment_id', 'segment_name', 'discount']\n",
      "First 5 rows:\n",
      "    customer_id  segment_id segment_name  discount\n",
      "0            1           2      Regular         3\n",
      "1            2           3        Loyal         4\n",
      "2            3           2      Regular         3\n",
      "3            4           1          New         2\n",
      "4            5           1          New         2\n",
      "\n",
      "DataFrame: customer_preferenced_contact_type\n",
      "Columns: ['customer_id', 'contact_type_id', 'contact_type']\n",
      "First 5 rows:\n",
      "    customer_id  contact_type_id        contact_type\n",
      "0            1                1               Email\n",
      "1            1                3                 SMS\n",
      "2            1                4        Social Media\n",
      "3            2                2               Phone\n",
      "4            2                5  Push Notifications\n"
     ]
    }
   ],
   "source": [
    "customer_preferenced_contact_type = frames_merge(splitted_dataframes, 'customer_preferenced_contact_type', 'contact_preference', 'contact_type_id', 'contact_id', 'customer_preferenced_contact_type')\n",
    "\n",
    "show_frames(splitted_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame: product\n",
      "Columns: ['id', 'product_name', 'category_name', 'price']\n",
      "First 5 rows:\n",
      "    id            product_name category_name  price\n",
      "0   1        The Great Gatsby         Books  10.99\n",
      "1   2                    1984         Books   9.99\n",
      "2   3  The Catcher in the Rye         Books   8.99\n",
      "3   4   To Kill a Mockingbird         Books  12.99\n",
      "4   5     Pride and Prejudice         Books  11.49\n",
      "5   6               Moby Dick         Books  14.99\n",
      "\n",
      "DataFrame: product_feedback\n",
      "Columns: ['id', 'purchase_id', 'rating', 'review']\n",
      "First 5 rows:\n",
      "    id  purchase_id  rating                                 review\n",
      "0   1  293813371.0       9                     Excellent service!\n",
      "1   2  696524227.0       8       Everything was great, thank you!\n",
      "2   3   14417739.0      10          Outstanding customer service!\n",
      "3   5  691165168.0       6  Quality did not meet my expectations.\n",
      "4   6  633302470.0       5                    Average experience.\n",
      "5   7  727560573.0       9              Really loved the product!\n",
      "\n",
      "DataFrame: purchase\n",
      "Columns: ['id', 'user_id', 'product_id', 'purchase_date', 'quantity']\n",
      "First 5 rows:\n",
      "           id  user_id  product_id purchase_date  quantity\n",
      "0  293813371       19         104    2024-02-09         2\n",
      "1  696524227       49          90    2023-06-30         1\n",
      "2   14417739       30          20    2023-09-28         1\n",
      "3  539614646       45         141    2023-04-25         2\n",
      "4  691165168       40          25    2023-10-26         2\n",
      "5  633302470        8          92    2023-09-15         1\n",
      "\n",
      "DataFrame: service_feedback\n",
      "Columns: ['id', 'customer_id', 'rating', 'comment']\n",
      "First 5 rows:\n",
      "    id  customer_id  rating                                 comment\n",
      "0   1            5       9  Excellent service, very helpful staff!\n",
      "1   2           12       7      Good service, but could be faster.\n",
      "2   3            3      10        Absolutely fantastic experience!\n",
      "3   4           25       8     Satisfied overall, would recommend.\n",
      "4   5           19       6      Service was okay, nothing special.\n",
      "5   6           34      10    Outstanding service, very impressed!\n",
      "\n",
      "DataFrame: customers_segmetns\n",
      "Columns: ['customer_id', 'segment_id', 'segment_name', 'discount']\n",
      "First 5 rows:\n",
      "    customer_id  segment_id segment_name  discount\n",
      "0            1           2      Regular         3\n",
      "1            2           3        Loyal         4\n",
      "2            3           2      Regular         3\n",
      "3            4           1          New         2\n",
      "4            5           1          New         2\n",
      "5            6           5     Employer         4\n",
      "\n",
      "DataFrame: customer_preferenced_contact_type\n",
      "Columns: ['customer_id', 'contact_type_id', 'contact_type']\n",
      "First 5 rows:\n",
      "    customer_id  contact_type_id        contact_type\n",
      "0            1                1               Email\n",
      "1            1                3                 SMS\n",
      "2            1                4        Social Media\n",
      "3            2                2               Phone\n",
      "4            2                5  Push Notifications\n",
      "5            3                1               Email\n",
      "\n",
      "DataFrame: customer\n",
      "Columns: ['id', 'name', 'email', 'location_id', 'registration_date', 'location_name']\n",
      "First 5 rows:\n",
      "    id     name                email  location_id registration_date  \\\n",
      "0   1    Alice    alice@example.com            1        2023-01-15   \n",
      "1   2      Bob      bob@example.com            2        2023-02-20   \n",
      "2   3  Charlie  charlie@example.com            3        2023-03-10   \n",
      "3   4    David    david@example.com            4        2023-04-25   \n",
      "4   5      Eva      eva@example.com            5        2023-05-30   \n",
      "5   6    Frank    frank@example.com            6        2023-06-01   \n",
      "\n",
      "   location_name  \n",
      "0       New York  \n",
      "1  San Francisco  \n",
      "2    Los Angeles  \n",
      "3        Chicago  \n",
      "4        Houston  \n",
      "5          Miami  \n"
     ]
    }
   ],
   "source": [
    "customer = frames_merge(splitted_dataframes, 'customer', 'location', 'location_id', 'location_id', 'customer')\n",
    "\n",
    "show_frames(splitted_dataframes,samples=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame: product_feedback\n",
      "Columns: ['id', 'purchase_id', 'rating', 'review']\n",
      "First 5 rows:\n",
      "    id  purchase_id  rating                                 review\n",
      "0   1  293813371.0       9                     Excellent service!\n",
      "1   2  696524227.0       8       Everything was great, thank you!\n",
      "2   3   14417739.0      10          Outstanding customer service!\n",
      "3   5  691165168.0       6  Quality did not meet my expectations.\n",
      "4   6  633302470.0       5                    Average experience.\n",
      "5   7  727560573.0       9              Really loved the product!\n",
      "\n",
      "DataFrame: service_feedback\n",
      "Columns: ['id', 'customer_id', 'rating', 'comment']\n",
      "First 5 rows:\n",
      "    id  customer_id  rating                                 comment\n",
      "0   1            5       9  Excellent service, very helpful staff!\n",
      "1   2           12       7      Good service, but could be faster.\n",
      "2   3            3      10        Absolutely fantastic experience!\n",
      "3   4           25       8     Satisfied overall, would recommend.\n",
      "4   5           19       6      Service was okay, nothing special.\n",
      "5   6           34      10    Outstanding service, very impressed!\n",
      "\n",
      "DataFrame: customers_segmetns\n",
      "Columns: ['customer_id', 'segment_id', 'segment_name', 'discount']\n",
      "First 5 rows:\n",
      "    customer_id  segment_id segment_name  discount\n",
      "0            1           2      Regular         3\n",
      "1            2           3        Loyal         4\n",
      "2            3           2      Regular         3\n",
      "3            4           1          New         2\n",
      "4            5           1          New         2\n",
      "5            6           5     Employer         4\n",
      "\n",
      "DataFrame: customer_preferenced_contact_type\n",
      "Columns: ['customer_id', 'contact_type_id', 'contact_type']\n",
      "First 5 rows:\n",
      "    customer_id  contact_type_id        contact_type\n",
      "0            1                1               Email\n",
      "1            1                3                 SMS\n",
      "2            1                4        Social Media\n",
      "3            2                2               Phone\n",
      "4            2                5  Push Notifications\n",
      "5            3                1               Email\n",
      "\n",
      "DataFrame: customer\n",
      "Columns: ['id', 'name', 'email', 'location_id', 'registration_date', 'location_name']\n",
      "First 5 rows:\n",
      "    id     name                email  location_id registration_date  \\\n",
      "0   1    Alice    alice@example.com            1        2023-01-15   \n",
      "1   2      Bob      bob@example.com            2        2023-02-20   \n",
      "2   3  Charlie  charlie@example.com            3        2023-03-10   \n",
      "3   4    David    david@example.com            4        2023-04-25   \n",
      "4   5      Eva      eva@example.com            5        2023-05-30   \n",
      "5   6    Frank    frank@example.com            6        2023-06-01   \n",
      "\n",
      "   location_name  \n",
      "0       New York  \n",
      "1  San Francisco  \n",
      "2    Los Angeles  \n",
      "3        Chicago  \n",
      "4        Houston  \n",
      "5          Miami  \n",
      "\n",
      "DataFrame: purchase\n",
      "Columns: ['id', 'user_id', 'product_id', 'purchase_date', 'quantity', 'product_name', 'category_name', 'price']\n",
      "First 5 rows:\n",
      "           id  user_id  product_id purchase_date  quantity  \\\n",
      "0  293813371       19         104    2024-02-09         2   \n",
      "1  696524227       49          90    2023-06-30         1   \n",
      "2   14417739       30          20    2023-09-28         1   \n",
      "3  539614646       45         141    2023-04-25         2   \n",
      "4  691165168       40          25    2023-10-26         2   \n",
      "5  633302470        8          92    2023-09-15         1   \n",
      "\n",
      "                            product_name category_name  price  \n",
      "0                           Finding Nemo        Movies   9.99  \n",
      "1                          Borderlands 3         Games  59.99  \n",
      "2                           The Bell Jar         Books   9.99  \n",
      "3                         A Star Is Born        Movies  14.99  \n",
      "4  Harry Potter and the Sorcerer's Stone         Books  12.99  \n",
      "5                       Dead by Daylight         Games  29.99  \n"
     ]
    }
   ],
   "source": [
    "purchase = frames_merge(splitted_dataframes, 'purchase', 'product', 'product_id', 'id', 'purchase')\n",
    "\n",
    "show_frames(splitted_dataframes,samples=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame: product_feedback\n",
      "Columns: ['id', 'purchase_id', 'rating', 'review']\n",
      "First 5 rows:\n",
      "    id  purchase_id  rating                                 review\n",
      "0   1  293813371.0       9                     Excellent service!\n",
      "1   2  696524227.0       8       Everything was great, thank you!\n",
      "2   3   14417739.0      10          Outstanding customer service!\n",
      "3   5  691165168.0       6  Quality did not meet my expectations.\n",
      "4   6  633302470.0       5                    Average experience.\n",
      "5   7  727560573.0       9              Really loved the product!\n",
      "6   9    9627136.0      10               Best purchase I’ve made!\n",
      "7  11  536015025.0       8            Would recommend to friends.\n",
      "8  12  386075240.0       7    Fast shipping, but item was flawed.\n",
      "9  13  203222787.0       9           Satisfied with the purchase!\n",
      "\n",
      "DataFrame: service_feedback\n",
      "Columns: ['id', 'customer_id', 'rating', 'comment']\n",
      "First 5 rows:\n",
      "    id  customer_id  rating                                  comment\n",
      "0   1            5       9   Excellent service, very helpful staff!\n",
      "1   2           12       7       Good service, but could be faster.\n",
      "2   3            3      10         Absolutely fantastic experience!\n",
      "3   4           25       8      Satisfied overall, would recommend.\n",
      "4   5           19       6       Service was okay, nothing special.\n",
      "5   6           34      10     Outstanding service, very impressed!\n",
      "6   7            2       5          Disappointed, had a few issues.\n",
      "7   8           17       9  Very pleased with the customer support.\n",
      "8   9            8       8  Good service, happy with my experience.\n",
      "9  10           50      10         Best service I've ever received!\n",
      "\n",
      "DataFrame: customers_segmetns\n",
      "Columns: ['customer_id', 'segment_name', 'discount']\n",
      "First 5 rows:\n",
      "    customer_id segment_name  discount\n",
      "0            1      Regular         3\n",
      "1            2        Loyal         4\n",
      "2            3      Regular         3\n",
      "3            4          New         2\n",
      "4            5          New         2\n",
      "5            6     Employer         4\n",
      "6            7          New         2\n",
      "7            8          New         2\n",
      "8            9          New         2\n",
      "9           10          New         2\n",
      "\n",
      "DataFrame: customer_preferenced_contact_type\n",
      "Columns: ['customer_id', 'contact_type']\n",
      "First 5 rows:\n",
      "    customer_id        contact_type\n",
      "0            1               Email\n",
      "1            1                 SMS\n",
      "2            1        Social Media\n",
      "3            2               Phone\n",
      "4            2  Push Notifications\n",
      "5            3               Email\n",
      "6            3               Phone\n",
      "7            3    In-App Messaging\n",
      "8            4                 SMS\n",
      "9            5               Email\n",
      "\n",
      "DataFrame: customer\n",
      "Columns: ['id', 'name', 'email', 'registration_date', 'location_name']\n",
      "First 5 rows:\n",
      "    id     name                email registration_date  location_name\n",
      "0   1    Alice    alice@example.com        2023-01-15       New York\n",
      "1   2      Bob      bob@example.com        2023-02-20  San Francisco\n",
      "2   3  Charlie  charlie@example.com        2023-03-10    Los Angeles\n",
      "3   4    David    david@example.com        2023-04-25        Chicago\n",
      "4   5      Eva      eva@example.com        2023-05-30        Houston\n",
      "5   6    Frank    frank@example.com        2023-06-01          Miami\n",
      "6   7    Grace    grace@example.com        2023-06-15        Seattle\n",
      "7   8    Henry    henry@example.com        2023-06-30         Boston\n",
      "8   9      Ivy      ivy@example.com        2023-07-10        Atlanta\n",
      "9  10     Jack     jack@example.com        2023-07-25         Denver\n",
      "\n",
      "DataFrame: purchase\n",
      "Columns: ['id', 'user_id', 'purchase_date', 'quantity', 'product_name', 'category_name', 'price']\n",
      "First 5 rows:\n",
      "           id  user_id purchase_date  quantity  \\\n",
      "0  293813371       19    2024-02-09         2   \n",
      "1  696524227       49    2023-06-30         1   \n",
      "2   14417739       30    2023-09-28         1   \n",
      "3  539614646       45    2023-04-25         2   \n",
      "4  691165168       40    2023-10-26         2   \n",
      "5  633302470        8    2023-09-15         1   \n",
      "6  727560573        9    2023-08-30         2   \n",
      "7  683861597       47    2024-01-11         2   \n",
      "8    9627136        2    2024-01-19         2   \n",
      "9  227811136       22    2023-11-02         2   \n",
      "\n",
      "                            product_name category_name  price  \n",
      "0                           Finding Nemo        Movies   9.99  \n",
      "1                          Borderlands 3         Games  59.99  \n",
      "2                           The Bell Jar         Books   9.99  \n",
      "3                         A Star Is Born        Movies  14.99  \n",
      "4  Harry Potter and the Sorcerer's Stone         Books  12.99  \n",
      "5                       Dead by Daylight         Games  29.99  \n",
      "6                               Tekken 7         Games  29.99  \n",
      "7                      The Little Prince         Books   7.99  \n",
      "8                The Wolf of Wall Street        Movies  14.99  \n",
      "9                             Fight Club        Movies  12.99  \n"
     ]
    }
   ],
   "source": [
    "splitted_dataframes['customers_segmetns'].drop('segment_id', axis=1, inplace=True)\n",
    "splitted_dataframes['customer_preferenced_contact_type'].drop('contact_type_id', axis=1, inplace=True)\n",
    "splitted_dataframes['customer'].drop('location_id', axis=1, inplace=True)\n",
    "splitted_dataframes['purchase'].drop('product_id', axis=1, inplace=True)\n",
    "\n",
    "show_frames(splitted_dataframes,samples=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame: product_feedback\n",
      "Columns: ['id', 'purchase_id', 'rating', 'review']\n",
      "First 5 rows:\n",
      "    id  purchase_id  rating                                 review\n",
      "0   1  293813371.0       9                     Excellent service!\n",
      "1   2  696524227.0       8       Everything was great, thank you!\n",
      "2   3   14417739.0      10          Outstanding customer service!\n",
      "3   5  691165168.0       6  Quality did not meet my expectations.\n",
      "4   6  633302470.0       5                    Average experience.\n",
      "5   7  727560573.0       9              Really loved the product!\n",
      "\n",
      "DataFrame: customers_segmetns\n",
      "Columns: ['customer_id', 'segment_name', 'discount']\n",
      "First 5 rows:\n",
      "    customer_id segment_name  discount\n",
      "0            1      Regular         3\n",
      "1            2        Loyal         4\n",
      "2            3      Regular         3\n",
      "3            4          New         2\n",
      "4            5          New         2\n",
      "5            6     Employer         4\n",
      "\n",
      "DataFrame: customer\n",
      "Columns: ['id', 'name', 'email', 'registration_date', 'location_name']\n",
      "First 5 rows:\n",
      "    id     name                email registration_date  location_name\n",
      "0   1    Alice    alice@example.com        2023-01-15       New York\n",
      "1   2      Bob      bob@example.com        2023-02-20  San Francisco\n",
      "2   3  Charlie  charlie@example.com        2023-03-10    Los Angeles\n",
      "3   4    David    david@example.com        2023-04-25        Chicago\n",
      "4   5      Eva      eva@example.com        2023-05-30        Houston\n",
      "5   6    Frank    frank@example.com        2023-06-01          Miami\n",
      "\n",
      "DataFrame: purchase\n",
      "Columns: ['id', 'user_id', 'purchase_date', 'quantity', 'product_name', 'category_name', 'price']\n",
      "First 5 rows:\n",
      "           id  user_id purchase_date  quantity  \\\n",
      "0  293813371       19    2024-02-09         2   \n",
      "1  696524227       49    2023-06-30         1   \n",
      "2   14417739       30    2023-09-28         1   \n",
      "3  539614646       45    2023-04-25         2   \n",
      "4  691165168       40    2023-10-26         2   \n",
      "5  633302470        8    2023-09-15         1   \n",
      "\n",
      "                            product_name category_name  price  \n",
      "0                           Finding Nemo        Movies   9.99  \n",
      "1                          Borderlands 3         Games  59.99  \n",
      "2                           The Bell Jar         Books   9.99  \n",
      "3                         A Star Is Born        Movies  14.99  \n",
      "4  Harry Potter and the Sorcerer's Stone         Books  12.99  \n",
      "5                       Dead by Daylight         Games  29.99  \n",
      "\n",
      "DataFrame: service_feedback\n",
      "Columns: ['id', 'customer_id', 'rating', 'comment', 'contact_type']\n",
      "First 5 rows:\n",
      "    id  customer_id  rating                                 comment  \\\n",
      "0   1            5       9  Excellent service, very helpful staff!   \n",
      "0   1            5       9  Excellent service, very helpful staff!   \n",
      "0   1            5       9  Excellent service, very helpful staff!   \n",
      "0   1            5       9  Excellent service, very helpful staff!   \n",
      "0   1            5       9  Excellent service, very helpful staff!   \n",
      "1   2           12       7      Good service, but could be faster.   \n",
      "\n",
      "         contact_type  \n",
      "0               Email  \n",
      "0               Phone  \n",
      "0                 SMS  \n",
      "0        Social Media  \n",
      "0  Push Notifications  \n",
      "1               Phone  \n"
     ]
    }
   ],
   "source": [
    "service_feedback = frames_merge(splitted_dataframes, 'service_feedback', 'customer_preferenced_contact_type', 'customer_id', 'customer_id', 'service_feedback')\n",
    "\n",
    "show_frames(splitted_dataframes,samples=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame: product_feedback\n",
      "Columns: ['id', 'purchase_id', 'rating', 'review']\n",
      "First 5 rows:\n",
      "    id  purchase_id  rating                                 review\n",
      "0   1  293813371.0       9                     Excellent service!\n",
      "1   2  696524227.0       8       Everything was great, thank you!\n",
      "2   3   14417739.0      10          Outstanding customer service!\n",
      "3   5  691165168.0       6  Quality did not meet my expectations.\n",
      "4   6  633302470.0       5                    Average experience.\n",
      "5   7  727560573.0       9              Really loved the product!\n",
      "\n",
      "DataFrame: customer\n",
      "Columns: ['id', 'name', 'email', 'registration_date', 'location_name']\n",
      "First 5 rows:\n",
      "    id     name                email registration_date  location_name\n",
      "0   1    Alice    alice@example.com        2023-01-15       New York\n",
      "1   2      Bob      bob@example.com        2023-02-20  San Francisco\n",
      "2   3  Charlie  charlie@example.com        2023-03-10    Los Angeles\n",
      "3   4    David    david@example.com        2023-04-25        Chicago\n",
      "4   5      Eva      eva@example.com        2023-05-30        Houston\n",
      "5   6    Frank    frank@example.com        2023-06-01          Miami\n",
      "\n",
      "DataFrame: purchase\n",
      "Columns: ['id', 'user_id', 'purchase_date', 'quantity', 'product_name', 'category_name', 'price']\n",
      "First 5 rows:\n",
      "           id  user_id purchase_date  quantity  \\\n",
      "0  293813371       19    2024-02-09         2   \n",
      "1  696524227       49    2023-06-30         1   \n",
      "2   14417739       30    2023-09-28         1   \n",
      "3  539614646       45    2023-04-25         2   \n",
      "4  691165168       40    2023-10-26         2   \n",
      "5  633302470        8    2023-09-15         1   \n",
      "\n",
      "                            product_name category_name  price  \n",
      "0                           Finding Nemo        Movies   9.99  \n",
      "1                          Borderlands 3         Games  59.99  \n",
      "2                           The Bell Jar         Books   9.99  \n",
      "3                         A Star Is Born        Movies  14.99  \n",
      "4  Harry Potter and the Sorcerer's Stone         Books  12.99  \n",
      "5                       Dead by Daylight         Games  29.99  \n",
      "\n",
      "DataFrame: service_feedback\n",
      "Columns: ['id', 'customer_id', 'rating', 'comment', 'segment_name', 'discount', 'contact_type']\n",
      "First 5 rows:\n",
      "    id  customer_id  rating                                 comment  \\\n",
      "0   1            5       9  Excellent service, very helpful staff!   \n",
      "1   2           12       7      Good service, but could be faster.   \n",
      "2   3            3      10        Absolutely fantastic experience!   \n",
      "3   4           25       8     Satisfied overall, would recommend.   \n",
      "4   5           19       6      Service was okay, nothing special.   \n",
      "5   6           34      10    Outstanding service, very impressed!   \n",
      "\n",
      "  segment_name  discount                                       contact_type  \n",
      "0          New         2  Email, Phone, SMS, Social Media, Push Notifica...  \n",
      "1          New         2                           Phone, SMS, Social Media  \n",
      "2      Regular         3                     Email, Phone, In-App Messaging  \n",
      "3          New         2                   Email, Phone, Push Notifications  \n",
      "4          New         2                                       Email, Phone  \n",
      "5          New         2            Phone, Social Media, Push Notifications  \n"
     ]
    }
   ],
   "source": [
    "service_feedback = frames_merge(splitted_dataframes, 'service_feedback', 'customers_segmetns', 'customer_id', 'customer_id', 'service_feedback')\n",
    "service_feedback['service_feedback'] = service_feedback['service_feedback'].groupby(['id', 'customer_id', 'rating', 'comment', 'segment_name', 'discount'], as_index=False).agg({\n",
    "    'contact_type': ', '.join }) # Объединяем контактные типы в одну строку, разделяя запятой\n",
    "show_frames(splitted_dataframes,samples=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame: customer\n",
      "Columns: ['id', 'name', 'email', 'registration_date', 'location_name']\n",
      "First 5 rows:\n",
      "     id     name                email registration_date  location_name\n",
      "0    1    Alice    alice@example.com        2023-01-15       New York\n",
      "1    2      Bob      bob@example.com        2023-02-20  San Francisco\n",
      "2    3  Charlie  charlie@example.com        2023-03-10    Los Angeles\n",
      "3    4    David    david@example.com        2023-04-25        Chicago\n",
      "4    5      Eva      eva@example.com        2023-05-30        Houston\n",
      "5    6    Frank    frank@example.com        2023-06-01          Miami\n",
      "6    7    Grace    grace@example.com        2023-06-15        Seattle\n",
      "7    8    Henry    henry@example.com        2023-06-30         Boston\n",
      "8    9      Ivy      ivy@example.com        2023-07-10        Atlanta\n",
      "9   10     Jack     jack@example.com        2023-07-25         Denver\n",
      "10  11      Kim      kim@example.com        2023-08-05       New York\n",
      "11  12     Liam     liam@example.com        2023-08-15  San Francisco\n",
      "12  13      Mia      mia@example.com        2023-08-25    Los Angeles\n",
      "13  14     Noah     noah@example.com        2023-09-05        Chicago\n",
      "14  15   Olivia   olivia@example.com        2023-09-15        Houston\n",
      "15  16     Paul     paul@example.com        2023-09-20          Miami\n",
      "16  17    Quinn    quinn@example.com        2023-09-30        Seattle\n",
      "17  18     Ryan     ryan@example.com        2023-10-05         Boston\n",
      "18  19    Sarah    sarah@example.com        2023-10-10        Atlanta\n",
      "19  20      Tom      tom@example.com        2023-10-15         Denver\n",
      "\n",
      "DataFrame: service_feedback\n",
      "Columns: ['id', 'customer_id', 'rating', 'comment', 'segment_name', 'discount', 'contact_type']\n",
      "First 5 rows:\n",
      "     id  customer_id  rating                                     comment  \\\n",
      "0    1            5       9      Excellent service, very helpful staff!   \n",
      "1    2           12       7          Good service, but could be faster.   \n",
      "2    3            3      10            Absolutely fantastic experience!   \n",
      "3    4           25       8         Satisfied overall, would recommend.   \n",
      "4    5           19       6          Service was okay, nothing special.   \n",
      "5    6           34      10        Outstanding service, very impressed!   \n",
      "6    7            2       5             Disappointed, had a few issues.   \n",
      "7    8           17       9     Very pleased with the customer support.   \n",
      "8    9            8       8     Good service, happy with my experience.   \n",
      "9   10           50      10            Best service I've ever received!   \n",
      "10  11           29       6              Just average, could be better.   \n",
      "11  12            1       7  Satisfactory service, nothing exceptional.   \n",
      "12  13           35      10         Incredible service, will come back!   \n",
      "13  14           24       9            Very helpful and friendly staff!   \n",
      "14  15           43       5            Not great, had several problems.   \n",
      "15  16           10       8   Good overall experience, would recommend.   \n",
      "16  17           11       6             Average service, expected more.   \n",
      "17  18           36      10           Highly recommend, very satisfied!   \n",
      "18  19            4       7             Decent service, but a bit slow.   \n",
      "19  20           20       9  Really impressed with the attention given!   \n",
      "\n",
      "   segment_name  discount                                       contact_type  \n",
      "0           New         2  Email, Phone, SMS, Social Media, Push Notifica...  \n",
      "1           New         2                           Phone, SMS, Social Media  \n",
      "2       Regular         3                     Email, Phone, In-App Messaging  \n",
      "3           New         2                   Email, Phone, Push Notifications  \n",
      "4           New         2                                       Email, Phone  \n",
      "5           New         2            Phone, Social Media, Push Notifications  \n",
      "6         Loyal         4                          Phone, Push Notifications  \n",
      "7       Regular         3              Phone, Social Media, In-App Messaging  \n",
      "8           New         2            Email, Push Notifications, Social Media  \n",
      "9       Regular         3              Email, Phone, SMS, Push Notifications  \n",
      "10          VIP         5                     Phone, SMS, Push Notifications  \n",
      "11      Regular         3                           Email, SMS, Social Media  \n",
      "12          New         2                                       Email, Phone  \n",
      "13          New         2                                                SMS  \n",
      "14          New         2            Email, Social Media, Push Notifications  \n",
      "15          New         2                                Email, Social Media  \n",
      "16        Loyal         4                                       Email, Phone  \n",
      "17          VIP         5              Email, Social Media, In-App Messaging  \n",
      "18          New         2                                                SMS  \n",
      "19      Regular         3  SMS, Social Media, Push Notifications, In-App ...  \n",
      "\n",
      "DataFrame: purchase\n",
      "Columns: ['id', 'user_id', 'purchase_date', 'quantity', 'product_name', 'category_name', 'price', 'rating', 'review']\n",
      "First 5 rows:\n",
      "            id  user_id purchase_date  quantity  \\\n",
      "0   293813371       19    2024-02-09         2   \n",
      "1   696524227       49    2023-06-30         1   \n",
      "2    14417739       30    2023-09-28         1   \n",
      "3   539614646       45    2023-04-25         2   \n",
      "4   691165168       40    2023-10-26         2   \n",
      "5   633302470        8    2023-09-15         1   \n",
      "6   727560573        9    2023-08-30         2   \n",
      "7   683861597       47    2024-01-11         2   \n",
      "8     9627136        2    2024-01-19         2   \n",
      "9   227811136       22    2023-11-02         2   \n",
      "10  536015025       25    2023-10-06         1   \n",
      "11  386075240       47    2023-08-09         1   \n",
      "12  203222787        5    2023-09-14         1   \n",
      "13  276743573       25    2024-01-28         2   \n",
      "14  155974278        5    2023-12-27         1   \n",
      "15  356801462       46    2023-09-07         1   \n",
      "16  350589884       38    2023-09-28         1   \n",
      "17   67118060       16    2023-10-27         2   \n",
      "18  438824054       39    2023-06-24         2   \n",
      "19  291381826       39    2023-11-25         1   \n",
      "\n",
      "                             product_name category_name  price  rating  \\\n",
      "0                            Finding Nemo        Movies   9.99     9.0   \n",
      "1                           Borderlands 3         Games  59.99     8.0   \n",
      "2                            The Bell Jar         Books   9.99    10.0   \n",
      "3                          A Star Is Born        Movies  14.99     NaN   \n",
      "4   Harry Potter and the Sorcerer's Stone         Books  12.99     6.0   \n",
      "5                        Dead by Daylight         Games  29.99     5.0   \n",
      "6                                Tekken 7         Games  29.99     9.0   \n",
      "7                       The Little Prince         Books   7.99     NaN   \n",
      "8                 The Wolf of Wall Street        Movies  14.99    10.0   \n",
      "9                              Fight Club        Movies  12.99     NaN   \n",
      "10                              Jane Eyre         Books  10.99     8.0   \n",
      "11                     The Social Network        Movies  11.99     7.0   \n",
      "12                                Celeste         Games  19.99     9.0   \n",
      "13                             La La Land        Movies  14.99     NaN   \n",
      "14                      Wuthering Heights         Books   8.99     NaN   \n",
      "15                            Spiritfarer         Games  29.99     5.0   \n",
      "16                Where the Crawdads Sing         Books  12.99     NaN   \n",
      "17                       The Great Gatsby         Books  10.99     7.0   \n",
      "18                       A Beautiful Mind        Movies  14.99     9.0   \n",
      "19                              Chess Set         Games  29.99     6.0   \n",
      "\n",
      "                                   review  \n",
      "0                      Excellent service!  \n",
      "1        Everything was great, thank you!  \n",
      "2           Outstanding customer service!  \n",
      "3                                     NaN  \n",
      "4   Quality did not meet my expectations.  \n",
      "5                     Average experience.  \n",
      "6               Really loved the product!  \n",
      "7                                     NaN  \n",
      "8                Best purchase I’ve made!  \n",
      "9                                     NaN  \n",
      "10            Would recommend to friends.  \n",
      "11    Fast shipping, but item was flawed.  \n",
      "12           Satisfied with the purchase!  \n",
      "13                                    NaN  \n",
      "14                                    NaN  \n",
      "15         Disappointed with the product.  \n",
      "16                                    NaN  \n",
      "17               Good experience overall.  \n",
      "18                     Excellent quality!  \n",
      "19                   Not worth the money.  \n"
     ]
    }
   ],
   "source": [
    "splitted_dataframes['product_feedback'].drop('id', axis=1, inplace=True)\n",
    "\n",
    "purchase = frames_merge(splitted_dataframes, 'purchase', 'product_feedback', 'id', 'purchase_id', 'purchase')\n",
    "\n",
    "show_frames(splitted_dataframes,samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame: customer\n",
      "Columns: ['id', 'name', 'email', 'registration_date', 'location_name']\n",
      "First 5 rows:\n",
      "     id     name                email registration_date  location_name\n",
      "0    1    Alice    alice@example.com        2023-01-15       New York\n",
      "1    2      Bob      bob@example.com        2023-02-20  San Francisco\n",
      "2    3  Charlie  charlie@example.com        2023-03-10    Los Angeles\n",
      "3    4    David    david@example.com        2023-04-25        Chicago\n",
      "4    5      Eva      eva@example.com        2023-05-30        Houston\n",
      "5    6    Frank    frank@example.com        2023-06-01          Miami\n",
      "6    7    Grace    grace@example.com        2023-06-15        Seattle\n",
      "7    8    Henry    henry@example.com        2023-06-30         Boston\n",
      "8    9      Ivy      ivy@example.com        2023-07-10        Atlanta\n",
      "9   10     Jack     jack@example.com        2023-07-25         Denver\n",
      "10  11      Kim      kim@example.com        2023-08-05       New York\n",
      "11  12     Liam     liam@example.com        2023-08-15  San Francisco\n",
      "12  13      Mia      mia@example.com        2023-08-25    Los Angeles\n",
      "13  14     Noah     noah@example.com        2023-09-05        Chicago\n",
      "14  15   Olivia   olivia@example.com        2023-09-15        Houston\n",
      "15  16     Paul     paul@example.com        2023-09-20          Miami\n",
      "16  17    Quinn    quinn@example.com        2023-09-30        Seattle\n",
      "17  18     Ryan     ryan@example.com        2023-10-05         Boston\n",
      "18  19    Sarah    sarah@example.com        2023-10-10        Atlanta\n",
      "19  20      Tom      tom@example.com        2023-10-15         Denver\n",
      "\n",
      "DataFrame: purchase\n",
      "Columns: ['user_id', 'purchase_date', 'quantity', 'product_name', 'category_name', 'price', 'product_rating', 'review', 'service_rating', 'comment', 'segment_name', 'discount', 'contact_type']\n",
      "First 5 rows:\n",
      "     user_id purchase_date  quantity                           product_name  \\\n",
      "0        19    2024-02-09         2                           Finding Nemo   \n",
      "1        49    2023-06-30         1                          Borderlands 3   \n",
      "2        30    2023-09-28         1                           The Bell Jar   \n",
      "3        45    2023-04-25         2                         A Star Is Born   \n",
      "4        40    2023-10-26         2  Harry Potter and the Sorcerer's Stone   \n",
      "5         8    2023-09-15         1                       Dead by Daylight   \n",
      "6         9    2023-08-30         2                               Tekken 7   \n",
      "7        47    2024-01-11         2                      The Little Prince   \n",
      "8         2    2024-01-19         2                The Wolf of Wall Street   \n",
      "9        22    2023-11-02         2                             Fight Club   \n",
      "10       25    2023-10-06         1                              Jane Eyre   \n",
      "11       47    2023-08-09         1                     The Social Network   \n",
      "12        5    2023-09-14         1                                Celeste   \n",
      "13       25    2024-01-28         2                             La La Land   \n",
      "14        5    2023-12-27         1                      Wuthering Heights   \n",
      "15       46    2023-09-07         1                            Spiritfarer   \n",
      "16       38    2023-09-28         1                Where the Crawdads Sing   \n",
      "17       16    2023-10-27         2                       The Great Gatsby   \n",
      "18       39    2023-06-24         2                       A Beautiful Mind   \n",
      "19       39    2023-11-25         1                              Chess Set   \n",
      "\n",
      "   category_name  price  product_rating  \\\n",
      "0         Movies   9.99             9.0   \n",
      "1          Games  59.99             8.0   \n",
      "2          Books   9.99            10.0   \n",
      "3         Movies  14.99             NaN   \n",
      "4          Books  12.99             6.0   \n",
      "5          Games  29.99             5.0   \n",
      "6          Games  29.99             9.0   \n",
      "7          Books   7.99             NaN   \n",
      "8         Movies  14.99            10.0   \n",
      "9         Movies  12.99             NaN   \n",
      "10         Books  10.99             8.0   \n",
      "11        Movies  11.99             7.0   \n",
      "12         Games  19.99             9.0   \n",
      "13        Movies  14.99             NaN   \n",
      "14         Books   8.99             NaN   \n",
      "15         Games  29.99             5.0   \n",
      "16         Books  12.99             NaN   \n",
      "17         Books  10.99             7.0   \n",
      "18        Movies  14.99             9.0   \n",
      "19         Games  29.99             6.0   \n",
      "\n",
      "                                   review  service_rating  \\\n",
      "0                      Excellent service!             6.0   \n",
      "1        Everything was great, thank you!             NaN   \n",
      "2           Outstanding customer service!             9.0   \n",
      "3                                     NaN             NaN   \n",
      "4   Quality did not meet my expectations.             NaN   \n",
      "5                     Average experience.             8.0   \n",
      "6               Really loved the product!             6.0   \n",
      "7                                     NaN             NaN   \n",
      "8                Best purchase I’ve made!             5.0   \n",
      "9                                     NaN             5.0   \n",
      "10            Would recommend to friends.             8.0   \n",
      "11    Fast shipping, but item was flawed.             NaN   \n",
      "12           Satisfied with the purchase!             9.0   \n",
      "13                                    NaN             8.0   \n",
      "14                                    NaN             9.0   \n",
      "15         Disappointed with the product.             NaN   \n",
      "16                                    NaN             NaN   \n",
      "17               Good experience overall.             NaN   \n",
      "18                     Excellent quality!             NaN   \n",
      "19                   Not worth the money.             NaN   \n",
      "\n",
      "                                        comment segment_name  discount  \\\n",
      "0            Service was okay, nothing special.          New       2.0   \n",
      "1                                           NaN          NaN       NaN   \n",
      "2          Very reliable and efficient service.        Loyal       4.0   \n",
      "3                                           NaN          NaN       NaN   \n",
      "4                                           NaN          NaN       NaN   \n",
      "5       Good service, happy with my experience.          New       2.0   \n",
      "6   Service was just okay, nothing outstanding.          New       2.0   \n",
      "7                                           NaN          NaN       NaN   \n",
      "8               Disappointed, had a few issues.        Loyal       4.0   \n",
      "9             Disappointing experience overall.          New       2.0   \n",
      "10          Satisfied overall, would recommend.          New       2.0   \n",
      "11                                          NaN          NaN       NaN   \n",
      "12       Excellent service, very helpful staff!          New       2.0   \n",
      "13          Satisfied overall, would recommend.          New       2.0   \n",
      "14       Excellent service, very helpful staff!          New       2.0   \n",
      "15                                          NaN          NaN       NaN   \n",
      "16                                          NaN          NaN       NaN   \n",
      "17                                          NaN          NaN       NaN   \n",
      "18                                          NaN          NaN       NaN   \n",
      "19                                          NaN          NaN       NaN   \n",
      "\n",
      "                                         contact_type  \n",
      "0                                        Email, Phone  \n",
      "1                                                 NaN  \n",
      "2                             Email, In-App Messaging  \n",
      "3                                                 NaN  \n",
      "4                                                 NaN  \n",
      "5             Email, Push Notifications, Social Media  \n",
      "6                        Phone, SMS, In-App Messaging  \n",
      "7                                                 NaN  \n",
      "8                           Phone, Push Notifications  \n",
      "9                                          Phone, SMS  \n",
      "10                   Email, Phone, Push Notifications  \n",
      "11                                                NaN  \n",
      "12  Email, Phone, SMS, Social Media, Push Notifica...  \n",
      "13                   Email, Phone, Push Notifications  \n",
      "14  Email, Phone, SMS, Social Media, Push Notifica...  \n",
      "15                                                NaN  \n",
      "16                                                NaN  \n",
      "17                                                NaN  \n",
      "18                                                NaN  \n",
      "19                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "splitted_dataframes['service_feedback'].drop('id', axis=1, inplace=True)\n",
    "splitted_dataframes['purchase'].drop('id', axis=1, inplace=True)\n",
    "splitted_dataframes['purchase'].rename(columns = {'rating':'product_rating'}, inplace=True)\n",
    "splitted_dataframes['service_feedback'].rename(columns = {'rating':'service_rating'}, inplace=True)\n",
    "purchase = frames_merge(splitted_dataframes, 'purchase', 'service_feedback', 'user_id', 'customer_id', 'purchase')\n",
    "show_frames(splitted_dataframes,samples=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame: customer\n",
      "Columns: ['id', 'name', 'email', 'registration_date', 'location_name', 'purchase_date', 'quantity', 'product_name', 'category_name', 'price', 'product_rating', 'review', 'service_rating', 'comment', 'segment_name', 'discount', 'contact_type']\n",
      "First 5 rows:\n",
      "     id     name                email registration_date  location_name  \\\n",
      "0    1    Alice    alice@example.com        2023-01-15       New York   \n",
      "1    1    Alice    alice@example.com        2023-01-15       New York   \n",
      "2    1    Alice    alice@example.com        2023-01-15       New York   \n",
      "3    1    Alice    alice@example.com        2023-01-15       New York   \n",
      "4    1    Alice    alice@example.com        2023-01-15       New York   \n",
      "5    1    Alice    alice@example.com        2023-01-15       New York   \n",
      "6    1    Alice    alice@example.com        2023-01-15       New York   \n",
      "7    1    Alice    alice@example.com        2023-01-15       New York   \n",
      "8    1    Alice    alice@example.com        2023-01-15       New York   \n",
      "9    1    Alice    alice@example.com        2023-01-15       New York   \n",
      "10   1    Alice    alice@example.com        2023-01-15       New York   \n",
      "11   2      Bob      bob@example.com        2023-02-20  San Francisco   \n",
      "12   2      Bob      bob@example.com        2023-02-20  San Francisco   \n",
      "13   2      Bob      bob@example.com        2023-02-20  San Francisco   \n",
      "14   2      Bob      bob@example.com        2023-02-20  San Francisco   \n",
      "15   2      Bob      bob@example.com        2023-02-20  San Francisco   \n",
      "16   2      Bob      bob@example.com        2023-02-20  San Francisco   \n",
      "17   2      Bob      bob@example.com        2023-02-20  San Francisco   \n",
      "18   2      Bob      bob@example.com        2023-02-20  San Francisco   \n",
      "19   2      Bob      bob@example.com        2023-02-20  San Francisco   \n",
      "20   2      Bob      bob@example.com        2023-02-20  San Francisco   \n",
      "21   3  Charlie  charlie@example.com        2023-03-10    Los Angeles   \n",
      "22   3  Charlie  charlie@example.com        2023-03-10    Los Angeles   \n",
      "23   3  Charlie  charlie@example.com        2023-03-10    Los Angeles   \n",
      "24   3  Charlie  charlie@example.com        2023-03-10    Los Angeles   \n",
      "25   3  Charlie  charlie@example.com        2023-03-10    Los Angeles   \n",
      "26   3  Charlie  charlie@example.com        2023-03-10    Los Angeles   \n",
      "27   3  Charlie  charlie@example.com        2023-03-10    Los Angeles   \n",
      "28   3  Charlie  charlie@example.com        2023-03-10    Los Angeles   \n",
      "29   3  Charlie  charlie@example.com        2023-03-10    Los Angeles   \n",
      "\n",
      "   purchase_date  quantity                     product_name category_name  \\\n",
      "0     2024-01-28       1.0                          Journey         Games   \n",
      "1     2024-01-22       1.0                     Call of Duty         Games   \n",
      "2     2024-01-12       1.0                   The Art of War         Books   \n",
      "3     2024-01-20       1.0                       Life of Pi         Books   \n",
      "4     2023-09-11       2.0         The Shawshank Redemption        Movies   \n",
      "5     2024-02-08       2.0    Animal Crossing: New Horizons         Games   \n",
      "6     2024-02-04       2.0    Animal Crossing: New Horizons         Games   \n",
      "7     2023-07-13       1.0                   Gears of War 5         Games   \n",
      "8     2023-11-04       1.0                       Splatoon 2         Games   \n",
      "9     2024-01-18       2.0                   Cyberpunk 2077         Games   \n",
      "10    2023-12-16       2.0           The Fault in Our Stars         Books   \n",
      "11    2024-01-19       2.0          The Wolf of Wall Street        Movies   \n",
      "12    2024-02-08       2.0                  Resident Evil 3         Games   \n",
      "13    2023-09-04       1.0                    Jurassic Park        Movies   \n",
      "14    2023-12-02       2.0                         Zootopia        Movies   \n",
      "15    2023-08-26       2.0                             Halo         Games   \n",
      "16    2024-01-03       1.0                A Wrinkle in Time         Books   \n",
      "17    2023-09-04       2.0                  The Kite Runner         Books   \n",
      "18    2024-01-30       1.0                A Game of Thrones         Books   \n",
      "19    2024-01-29       2.0                   A Star Is Born        Movies   \n",
      "20    2023-09-27       1.0    Animal Crossing: New Horizons         Games   \n",
      "21    2023-10-27       2.0               The Shape of Water        Movies   \n",
      "22    2023-07-08       1.0                           Avatar        Movies   \n",
      "23    2023-12-11       1.0                             Coco        Movies   \n",
      "24    2023-08-23       2.0             Crime and Punishment         Books   \n",
      "25    2024-02-17       2.0  The Girl with the Dragon Tattoo         Books   \n",
      "26    2023-12-06       1.0                          FIFA 21         Games   \n",
      "27    2023-06-15       1.0         The Silence of the Lambs        Movies   \n",
      "28    2023-12-15       2.0                  The Dark Knight        Movies   \n",
      "29    2023-12-17       2.0             Anne of Green Gables         Books   \n",
      "\n",
      "    price  product_rating                            review  service_rating  \\\n",
      "0   14.99             5.0   Quality is lower than expected.             7.0   \n",
      "1   59.99             8.0         Very happy with my order!             7.0   \n",
      "2    7.99             9.0        Great quality and service!             7.0   \n",
      "3   10.99            10.0                Love this product!             7.0   \n",
      "4   14.99             6.0                Quality is subpar.             7.0   \n",
      "5   49.99             NaN                               NaN             7.0   \n",
      "6   49.99            10.0    Fantastic quality and service!             7.0   \n",
      "7   39.99             NaN                               NaN             7.0   \n",
      "8   59.99             NaN                               NaN             7.0   \n",
      "9   59.99             NaN                               NaN             7.0   \n",
      "10   9.99             NaN                               NaN             7.0   \n",
      "11  14.99            10.0          Best purchase I’ve made!             5.0   \n",
      "12  39.99             7.0          Good experience overall.             5.0   \n",
      "13  12.99             9.0         Great experience overall.             5.0   \n",
      "14  12.99             NaN                               NaN             5.0   \n",
      "15  59.99             9.0        Great service and quality!             5.0   \n",
      "16   9.49             7.0       Good, but had a few issues.             5.0   \n",
      "17  12.49             8.0   Satisfactory but could improve.             5.0   \n",
      "18  14.99            10.0                 Highly recommend!             5.0   \n",
      "19  14.99             5.0               Average experience.             5.0   \n",
      "20  49.99             NaN                               NaN             5.0   \n",
      "21  14.99             NaN                               NaN            10.0   \n",
      "22  19.99             7.0    Just okay, not worth the hype.            10.0   \n",
      "23  12.99             9.0  Great product, highly recommend!            10.0   \n",
      "24  15.99            10.0            Highly recommend this!            10.0   \n",
      "25  10.99             9.0         Great overall experience!            10.0   \n",
      "26  59.99             NaN                               NaN            10.0   \n",
      "27  12.99             NaN                               NaN            10.0   \n",
      "28  14.99             NaN                               NaN            10.0   \n",
      "29   8.99             NaN                               NaN            10.0   \n",
      "\n",
      "                                       comment segment_name  discount  \\\n",
      "0   Satisfactory service, nothing exceptional.      Regular       3.0   \n",
      "1   Satisfactory service, nothing exceptional.      Regular       3.0   \n",
      "2   Satisfactory service, nothing exceptional.      Regular       3.0   \n",
      "3   Satisfactory service, nothing exceptional.      Regular       3.0   \n",
      "4   Satisfactory service, nothing exceptional.      Regular       3.0   \n",
      "5   Satisfactory service, nothing exceptional.      Regular       3.0   \n",
      "6   Satisfactory service, nothing exceptional.      Regular       3.0   \n",
      "7   Satisfactory service, nothing exceptional.      Regular       3.0   \n",
      "8   Satisfactory service, nothing exceptional.      Regular       3.0   \n",
      "9   Satisfactory service, nothing exceptional.      Regular       3.0   \n",
      "10  Satisfactory service, nothing exceptional.      Regular       3.0   \n",
      "11             Disappointed, had a few issues.        Loyal       4.0   \n",
      "12             Disappointed, had a few issues.        Loyal       4.0   \n",
      "13             Disappointed, had a few issues.        Loyal       4.0   \n",
      "14             Disappointed, had a few issues.        Loyal       4.0   \n",
      "15             Disappointed, had a few issues.        Loyal       4.0   \n",
      "16             Disappointed, had a few issues.        Loyal       4.0   \n",
      "17             Disappointed, had a few issues.        Loyal       4.0   \n",
      "18             Disappointed, had a few issues.        Loyal       4.0   \n",
      "19             Disappointed, had a few issues.        Loyal       4.0   \n",
      "20             Disappointed, had a few issues.        Loyal       4.0   \n",
      "21            Absolutely fantastic experience!      Regular       3.0   \n",
      "22            Absolutely fantastic experience!      Regular       3.0   \n",
      "23            Absolutely fantastic experience!      Regular       3.0   \n",
      "24            Absolutely fantastic experience!      Regular       3.0   \n",
      "25            Absolutely fantastic experience!      Regular       3.0   \n",
      "26            Absolutely fantastic experience!      Regular       3.0   \n",
      "27            Absolutely fantastic experience!      Regular       3.0   \n",
      "28            Absolutely fantastic experience!      Regular       3.0   \n",
      "29            Absolutely fantastic experience!      Regular       3.0   \n",
      "\n",
      "                      contact_type  \n",
      "0         Email, SMS, Social Media  \n",
      "1         Email, SMS, Social Media  \n",
      "2         Email, SMS, Social Media  \n",
      "3         Email, SMS, Social Media  \n",
      "4         Email, SMS, Social Media  \n",
      "5         Email, SMS, Social Media  \n",
      "6         Email, SMS, Social Media  \n",
      "7         Email, SMS, Social Media  \n",
      "8         Email, SMS, Social Media  \n",
      "9         Email, SMS, Social Media  \n",
      "10        Email, SMS, Social Media  \n",
      "11       Phone, Push Notifications  \n",
      "12       Phone, Push Notifications  \n",
      "13       Phone, Push Notifications  \n",
      "14       Phone, Push Notifications  \n",
      "15       Phone, Push Notifications  \n",
      "16       Phone, Push Notifications  \n",
      "17       Phone, Push Notifications  \n",
      "18       Phone, Push Notifications  \n",
      "19       Phone, Push Notifications  \n",
      "20       Phone, Push Notifications  \n",
      "21  Email, Phone, In-App Messaging  \n",
      "22  Email, Phone, In-App Messaging  \n",
      "23  Email, Phone, In-App Messaging  \n",
      "24  Email, Phone, In-App Messaging  \n",
      "25  Email, Phone, In-App Messaging  \n",
      "26  Email, Phone, In-App Messaging  \n",
      "27  Email, Phone, In-App Messaging  \n",
      "28  Email, Phone, In-App Messaging  \n",
      "29  Email, Phone, In-App Messaging  \n"
     ]
    }
   ],
   "source": [
    "customer = pd.merge(\n",
    "    splitted_dataframes['customer'],\n",
    "    splitted_dataframes['purchase'],\n",
    "    left_on='id',         # колонка в customer\n",
    "    right_on='user_id',  # колонка в purchase\n",
    "    how='left',          # тип объединения\n",
    "    suffixes=('_1', '_2')  # суффиксы для дублирующихся колонок\n",
    ")\n",
    "customer.drop('user_id',axis=1, inplace=True);\n",
    "customer.head(40)\n",
    "new_splt = {}\n",
    "new_splt['customer'] = customer\n",
    "show_frames(new_splt,samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1     11\n",
       "2     10\n",
       "3     10\n",
       "4     14\n",
       "5      9\n",
       "6      7\n",
       "7      7\n",
       "8     13\n",
       "9     15\n",
       "10    10\n",
       "11    11\n",
       "12     5\n",
       "13     7\n",
       "14    15\n",
       "15     7\n",
       "16    11\n",
       "17    15\n",
       "18    10\n",
       "19    14\n",
       "20     4\n",
       "21    10\n",
       "22    10\n",
       "23     6\n",
       "24    12\n",
       "25    11\n",
       "26    15\n",
       "27     9\n",
       "28    15\n",
       "29     8\n",
       "30     7\n",
       "31    13\n",
       "32    10\n",
       "33     3\n",
       "34    10\n",
       "35    12\n",
       "36     7\n",
       "37     7\n",
       "38    13\n",
       "39     8\n",
       "40    15\n",
       "41     7\n",
       "42    12\n",
       "43    10\n",
       "44     4\n",
       "45    16\n",
       "46    11\n",
       "47    14\n",
       "48    11\n",
       "49     9\n",
       "50     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.groupby('id').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      14.99\n",
       "1      59.99\n",
       "2       7.99\n",
       "3      10.99\n",
       "4      14.99\n",
       "       ...  \n",
       "492    59.99\n",
       "493    12.49\n",
       "494    14.99\n",
       "495    59.99\n",
       "500      NaN\n",
       "Name: price, Length: 242, dtype: object"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.groupby('id')['price'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1     546.9248\n",
       "2     382.4064\n",
       "3     240.4145\n",
       "4     352.0846\n",
       "5     161.6118\n",
       "6       0.0000\n",
       "7       0.0000\n",
       "8     424.6536\n",
       "9     330.5442\n",
       "10    262.4930\n",
       "dtype: float64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer['price'] = pd.to_numeric(customer['price'], errors='coerce')\n",
    "customer['quantity'] = pd.to_numeric(customer['quantity'], errors='coerce')\n",
    "spent_per_customer = (customer['price'] * customer['quantity']  * (1 - customer['discount']/100)).groupby(customer['id']).sum()\n",
    "spent_per_customer.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVG pr RATING + HIGHEST pr RATING + THE MOST TIMES RATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           product_rating      \n",
      "                                     mean count\n",
      "product_name                                   \n",
      "Final Fantasy VII Remake             10.0     1\n",
      "Mario Kart 8 Deluxe                  10.0     1\n",
      "The Catcher in the Rye               10.0     2\n",
      "The Silence of the Lambs             10.0     1\n",
      "Toy Story                            10.0     1\n",
      "...                                   ...   ...\n",
      "The Picture of Dorian Gray            NaN     0\n",
      "The Shape of Water                    NaN     0\n",
      "To Kill a Mockingbird                 NaN     0\n",
      "War and Peace                         NaN     0\n",
      "Wuthering Heights                     NaN     0\n",
      "\n",
      "[144 rows x 2 columns]\n",
      "                      product_rating      \n",
      "                                mean count\n",
      "product_name                              \n",
      "The Road                        7.60     5\n",
      "A Star Is Born                  6.50     4\n",
      "The Kite Runner                 8.75     4\n",
      "Splatoon 2                      5.50     4\n",
      "Educated                        8.00     4\n",
      "...                              ...   ...\n",
      "The Matrix                       NaN     0\n",
      "The Shape of Water               NaN     0\n",
      "To Kill a Mockingbird            NaN     0\n",
      "War and Peace                    NaN     0\n",
      "Wuthering Heights                NaN     0\n",
      "\n",
      "[144 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "customer['product_rating'] = pd.to_numeric(customer['product_rating'], errors='coerce')\n",
    "average_rating_by_product = customer.groupby('product_name')['product_rating'].mean()\n",
    "rating_stats = customer.groupby('product_name').agg({\n",
    "    'product_rating': ['mean', 'count']\n",
    "}).round(2)\n",
    "rating_stats_sorted = rating_stats.sort_values(('product_rating', 'mean'), ascending=False)\n",
    "print(rating_stats_sorted)\n",
    "rating_stats_sorted = rating_stats.sort_values(('product_rating', 'count'), ascending=False)\n",
    "print(rating_stats_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POPULAR pr TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_name\n",
       "Games     181\n",
       "Books     173\n",
       "Movies    146\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer['category_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Доля трат по категориям для каждого пользователя (%):\n",
      "category_name  Books  Games  Movies\n",
      "id                                 \n",
      "1               6.91  87.77    5.32\n",
      "2              12.42  62.75   24.84\n",
      "3              33.06  24.20   42.74\n",
      "4              22.11  45.63   32.27\n",
      "5              33.32  57.59    9.09\n",
      "6               2.82  94.05    3.13\n",
      "7              30.24  18.52   51.24\n",
      "8              23.17  66.91    9.92\n",
      "9              24.74  26.67   48.59\n",
      "10             38.42  50.38   11.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Илья\\AppData\\Local\\Temp\\ipykernel_28600\\1043820562.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  user_category_spending = customer_df.groupby(['id', 'category_name']).apply(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "1     100.00\n",
       "2     100.01\n",
       "3     100.00\n",
       "4     100.01\n",
       "5     100.00\n",
       "6     100.00\n",
       "7     100.00\n",
       "8     100.00\n",
       "9     100.00\n",
       "10     99.99\n",
       "11    100.01\n",
       "12    100.00\n",
       "13    100.00\n",
       "14     99.99\n",
       "15    100.00\n",
       "16    100.01\n",
       "17    100.00\n",
       "18     99.99\n",
       "19     99.99\n",
       "20    100.00\n",
       "21    100.00\n",
       "22    100.00\n",
       "23    100.00\n",
       "24    100.00\n",
       "25    100.00\n",
       "26    100.00\n",
       "27    100.00\n",
       "28    100.00\n",
       "29    100.01\n",
       "30    100.01\n",
       "31     99.99\n",
       "32    100.00\n",
       "33    100.00\n",
       "34    100.00\n",
       "35    100.00\n",
       "36    100.00\n",
       "37    100.00\n",
       "38    100.00\n",
       "39     99.99\n",
       "40    100.00\n",
       "41    100.00\n",
       "42    100.00\n",
       "43    100.00\n",
       "44    100.00\n",
       "45    100.00\n",
       "46    100.00\n",
       "47    100.00\n",
       "48    100.00\n",
       "49    100.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_user_category_ratios(customer_df):\n",
    "    # Считаем траты для каждого пользователя по категориям\n",
    "    user_category_spending = customer_df.groupby(['id', 'category_name']).apply(\n",
    "        lambda x: (x['price'] * x['quantity']).sum()\n",
    "    ).unstack(fill_value=0)\n",
    "    \n",
    "    # Считаем общие траты каждого пользователя\n",
    "    user_total_spending = user_category_spending.sum(axis=1)\n",
    "    \n",
    "    # Считаем долю трат по категориям для каждого пользователя\n",
    "    user_category_ratios = user_category_spending.div(user_total_spending, axis=0) * 100\n",
    "\n",
    "    result = user_category_ratios.fillna(0)\n",
    "    \n",
    "    return result.round(2)\n",
    "\n",
    "# Применяем функцию\n",
    "user_category_ratios = calculate_user_category_ratios(customer)\n",
    "print(\"\\nДоля трат по категориям для каждого пользователя (%):\")\n",
    "print(user_category_ratios.head(10))\n",
    "user_category_ratios.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
